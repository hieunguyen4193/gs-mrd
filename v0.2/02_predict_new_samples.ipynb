{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.decomposition import NMF\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "import ot\n",
    "import pickle\n",
    "import argparse\n",
    "import Levenshtein\n",
    "import itertools\n",
    "from sklearn.metrics import roc_curve\n",
    "from helper_functions import *\n",
    "\n",
    "path_to_main_input = \"/media/hieunguyen/HNHD01/raw_data/MRD_GW_v1_20250318\"\n",
    "inputdir = os.path.join(path_to_main_input, \"Metadata_Genome-wide_Version1_07.03.25\")\n",
    "\n",
    "# test_batch_name = \"cmc_sample_20250326\"\n",
    "test_batch_name = \"Metadata_MRDGW_Track_progress_20250226\"\n",
    "\n",
    "PROJECT = \"gs-mrd\"\n",
    "release_version = \"20250326\"\n",
    "\n",
    "expected_spec = 0.90\n",
    "# expected_spec = 0.95\n",
    "# expected_spec = 0.98\n",
    "# expected_spec = 0.99\n",
    "# expected_spec = 1\n",
    "\n",
    "##### configurations/paths\n",
    "path_to_main_src = \"/media/hieunguyen/HNSD01/src/gs-mrd/v0.2\"\n",
    "path_to_save_output = f\"{path_to_main_src}/output/{release_version}/SPEC_{expected_spec}\"\n",
    "path_to_save_feature_order = f\"{path_to_main_src}/output/{release_version}/feature_order\"\n",
    "\n",
    "os.system(f\"mkdir -p {path_to_save_output}\")\n",
    "os.system(f\"mkdir -p {path_to_save_feature_order}\")\n",
    "\n",
    "os.system(f\"mkdir -p {path_to_save_output}/models\")\n",
    "os.system(f\"mkdir -p {path_to_save_output}/results\")\n",
    "os.system(f\"mkdir -p {path_to_save_output}/new_prediction/{test_batch_name}\")\n",
    "\n",
    "path_to_input_test_data = os.path.join(path_to_main_input, \"makePrediction_data\", test_batch_name)\n",
    "##### read features in\n",
    "test_featuredf = dict()\n",
    "\n",
    "for f in [\"NUCLEOSOME\", \"FLEN\", \"EM\", \"IchorCNA\"]:\n",
    "    test_featuredf[f] = pd.read_csv(os.path.join(path_to_input_test_data, f\"{f}.csv\"))\n",
    "\n",
    "test_featuredf[\"IchorCNA\"].columns = [\"SampleID\", \"ichorCNA\"]\n",
    "\n",
    "##### distance matrix based on edit distance of End motif 4bp\n",
    "nucleotides = ['A', 'C', 'G', 'T']\n",
    "motifs = [''.join(p) for p in itertools.product(nucleotides, repeat=4)]\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "distance_matrix = pd.DataFrame(index=motifs, columns=motifs)\n",
    "\n",
    "# Compute the Levenshtein distance between each pair of 4-mer motifs\n",
    "for motif1 in motifs:\n",
    "    for motif2 in motifs:\n",
    "        distance_matrix.loc[motif1, motif2] = Levenshtein.distance(motif1, motif2)\n",
    "\n",
    "# Convert the distance matrix to integer type\n",
    "M_EM = distance_matrix.to_numpy().copy()\n",
    "M_EM /= M_EM.max() * 0.1\n",
    "\n",
    "\n",
    "cutoffdf = pd.read_excel(f\"{path_to_save_output}/models/cutoff_SPEC{expected_spec}.xlsx\")\n",
    "\n",
    "##### absolute difference between a sample and the reference\n",
    "# prepare references\n",
    "ref = dict()\n",
    "\n",
    "em_ref = pd.read_csv(f\"{path_to_save_output}/models/Healthy_reference_EM.csv\")\n",
    "em_ref.columns = [\"motif\", \"Healthy\"]\n",
    "ref[\"EM\"] = em_ref.copy()\n",
    "\n",
    "flen_ref = pd.read_csv(f\"{path_to_save_output}/models/Healthy_reference_FLEN.csv\")\n",
    "flen_ref.columns = [\"FLEN\", \"Healthy\"]\n",
    "ref[\"FLEN\"] = flen_ref.copy()\n",
    "\n",
    "nuc_ref = pd.read_csv(f\"{path_to_save_output}/models/Healthy_reference_NUCLEOSOME.csv\")\n",
    "nuc_ref.columns = [\"Nucleosome\", \"Healthy\"]\n",
    "ref[\"NUCLEOSOME\"] = nuc_ref.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(os.path.join(path_to_input_test_data, \"metadata.xlsx\"))\n",
    "if \"ichorCNA\" in metadata.columns:\n",
    "    metadata = metadata.drop(columns=[\"ichorCNA\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_featuredf[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [\"NUCLEOSOME\", \"FLEN\", \"EM\", \"IchorCNA\"]:\n",
    "    test_featuredf[f] = test_featuredf[f][test_featuredf[f][\"SampleID\"].isin(metadata[\"SampleID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = dict()\n",
    "\n",
    "all_samples = test_featuredf[\"FLEN\"].SampleID.unique()\n",
    "\n",
    "# add score EM, FLEN, NUCLEOSOME to test_features\n",
    "for f in [\"EM\", \"FLEN\", \"NUCLEOSOME\"]:\n",
    "    inputdf = test_featuredf[f].set_index(\"SampleID\").T.copy()\n",
    "    inputdf[\"Healthy\"] = ref[f][\"Healthy\"].values\n",
    "    for sampleid in all_samples:\n",
    "        inputdf[sampleid] = abs(inputdf[sampleid] - inputdf[\"Healthy\"])\n",
    "    input_scoredf = inputdf.drop(\"Healthy\", axis = 1).sum().reset_index()\n",
    "    input_scoredf.columns = [\"SampleID\", f\"{f}_score\"]\n",
    "    input_scoredf = input_scoredf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "    test_features[f\"{f}_score\"] = input_scoredf\n",
    "\n",
    "f = \"EM\"\n",
    "inputdf = test_featuredf[f].set_index(\"SampleID\").T\n",
    "\n",
    "em_shannondf = pd.DataFrame(data = inputdf.columns, columns = [\"SampleID\"])\n",
    "def calculate_em_shannon(x, inputdf):\n",
    "    tmpdf = inputdf[x].values\n",
    "    shannon = -np.sum([item * np.log2(item) for item in tmpdf])/256\n",
    "    return(shannon)\n",
    "em_shannondf[\"EM_shannon\"] = em_shannondf[\"SampleID\"].apply(lambda x: calculate_em_shannon(x, inputdf))\n",
    "em_shannondf = em_shannondf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "test_features[\"EM_shannon\"] = em_shannondf\n",
    "##### OT distance\n",
    "for f in [\"EM\", \"FLEN\", \"NUCLEOSOME\"]:\n",
    "    barycenter = pd.read_csv(f\"{path_to_save_output}/models/Healthy_OT_{f}_baryl2.csv\")\n",
    "    bary_l2 = barycenter.baryl2.to_numpy()\n",
    "    ot_scoredf = pd.DataFrame(data = all_samples, columns = [\"SampleID\"])\n",
    "    ot_scoredf[f\"OT_{f}\"] = ot_scoredf[\"SampleID\"].apply(lambda x: \n",
    "        calculate_ot_distance_to_healthy_nuc(x, \n",
    "                                             bary_l2, \n",
    "                                             test_featuredf[f].set_index(\"SampleID\").T, \n",
    "                                             n = test_featuredf[f].shape[1] - 1))\n",
    "    ot_scoredf = ot_scoredf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "    test_features[f\"OT_{f}\"] = ot_scoredf\n",
    "    \n",
    "test_features[\"ichorCNA\"] = test_featuredf[\"IchorCNA\"]\n",
    "\n",
    "for input_feature in [\"EM\", \"FLEN\", \"NUCLEOSOME\"]:\n",
    "    filename = os.path.join(path_to_save_output, \"models\", f'NMF_{input_feature}.sav')\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    X = test_featuredf[input_feature].set_index(\"SampleID\")\n",
    "    W = model.transform(X.to_numpy())\n",
    "    H = model.components_\n",
    "    nmf_signal_cancer = cutoffdf[cutoffdf[\"feature\"].str.contains(input_feature)][\"feature\"].values[0].split(\"_\")[2]\n",
    "    nmfdf = pd.DataFrame(data = W, columns = [\"V1\", \"V2\"])\n",
    "    nmfdf[\"SampleID\"] = list(X.index)\n",
    "    nmfdf[\"V1_scale\"] = nmfdf[[\"V1\", \"V2\"]].apply(lambda x: x[0]/sum(x), axis = 1)\n",
    "    nmfdf[\"V2_scale\"] = nmfdf[[\"V1\", \"V2\"]].apply(lambda x: x[1]/sum(x), axis = 1)\n",
    "    nmfdf = nmfdf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "    tmpdf = nmfdf[[\"SampleID\", f\"V{nmf_signal_cancer}_scale\"]].copy()\n",
    "    tmpdf.columns = [\"SampleID\", f\"NMF_{input_feature}_{nmf_signal_cancer}\"]\n",
    "    test_features[f\"NMF_{input_feature}_{nmf_signal_cancer}\"] = tmpdf.copy()\n",
    "test_outputdf = pd.DataFrame(data = metadata[\"SampleID\"].to_list(), columns = [\"SampleID\"])\n",
    "for feat in test_features.keys():\n",
    "    tmpdf = test_features[feat][[\"SampleID\", feat]]\n",
    "    tmpdf.columns = [\"SampleID\", feat]\n",
    "    test_outputdf = test_outputdf.merge(tmpdf, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "\n",
    "test_outputdf = test_outputdf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_to_save_output}/models/feature_combinations.pkl\", \"rb\") as f:\n",
    "        feature_combinations = pickle.load(f)\n",
    "\n",
    "def get_Sen_Spec_for_combi(combi, inputdf):\n",
    "    input_feats = combi.split(\",\")\n",
    "    tmpdf =  inputdf[[\"Label\"] + [f\"prediction_{i}\" for i in input_feats]]\n",
    "    tmpdf[\"sum\"] = tmpdf[[f\"prediction_{i}\" for i in input_feats]].sum(axis = 1)\n",
    "    tmpdf[\"prediction\"] = tmpdf[\"sum\"].apply(lambda x: 1 if x != 0 else 0)\n",
    "    sen = tmpdf[(tmpdf[\"prediction\"] == 1) & (tmpdf[\"Label\"] == 1)].shape[0]/tmpdf[tmpdf[\"Label\"]== 1].shape[0]\n",
    "    spec = tmpdf[(tmpdf[\"prediction\"] == 0) & (tmpdf[\"Label\"] == 0)].shape[0]/tmpdf[tmpdf[\"Label\"]== 0].shape[0]\n",
    "    return(sen, spec)\n",
    "\n",
    "all_features = test_features.keys()\n",
    "for feat in all_features:\n",
    "    c = float(cutoffdf[cutoffdf[\"feature\"] == feat].cutoff.values[0])\n",
    "    test_outputdf[f\"prediction_{feat}\"] = test_outputdf[feat].apply(\n",
    "        lambda x: 1 if x > c else 0\n",
    "    )\n",
    "test_combinedf = pd.DataFrame(data = [\",\".join(feature_combinations[i]) for i in range(len(feature_combinations))], \n",
    "                              columns = [\"feature_combinations\"])\n",
    "\n",
    "test_outputdf.to_excel(f\"{path_to_save_output}/new_prediction/{test_batch_name}/test_outputdf.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
